# Reading notes

The description of an experiment is done via *events* and their *probabilities*.

The *sample space* is the set of all possible *outcomes* of an experiment. 

An *event* is a subset of the *sample space*.

We can represent possible outcomes as *sets* or *probabilities*.

The probability space *finite*, *countably finite*, or *uncountably infinite*.
$$
\begin{array}{lc}
\hline \text { English } & \text { Sets } \\
\hline \text { Events and occurrences } & S \\
\text { sample space } & s \in S \\
s \text { is a possible outcome } & A \subseteq S \\
A \text { is an event } & s_{\text {actual }} \in A \\
A \text { occurred } & s_{\text {actual }} \in S \\
\text { something must happen } & \\
\hline \text { New events from old events } & A \cup B \\
A \text { or } B \text { (inclusive) } & A \cap B \\
A \text { and } B & A^c \\
\text { not } A & \left(A \cap B^c\right) \cup\left(A^c \cap B\right) \\
A \text { or } B, \text { but not both } & A_1 \cup \cdots \cup A_n \\
\text { at least one of } A_1, \ldots, A_n & A_1 \cap \cdots \cap A_n \\
\text { all of } A_1, \ldots, A_n & \\
\hline \text { Relationships between events } & A \subseteq B \\
A \text { implies } B & A \cap B=\emptyset \\
A \text { and } B \text { are mutually exclusive } & A_1 \cup \cdots \cup A_n=S, A_i \cap A_j=\emptyset \text { for } i \neq j \\
A_1, \ldots, A_n \text { are a partition of } S & \\
\hline
\end{array}
$$

**De Morgan's Law**:
$$
(A \cup B)^c=A^c \cap B^c
$$
$$
(A \cap B)^c=A^c \cup B^c
$$
**Definition 1.3.1** **(Naive definition of probability)**. Let $A$ be an event for an experiment with a finite sample space $S$. The naive probability of $A$ is
$$
P_{\text {naive }}(A)=\frac{|A|}{|S|}=\frac{\text { number of outcomes favorable to } A}{\text { total number of outcomes in } S}
$$
## Combinatorics

**Theorem 1.4.1 (Multiplication rule)**. Consider a compound experiment consisting of two sub-experiments, Experiment $A$ and Experiment $B$. Suppose that Experiment $A$ has $a$ possible outcomes, and for each of those outcomes Experiment $B$ has $b$ possible outcomes. Then the compound experiment has $a b$ possible outcomes.

### Tree diagram ("counting trees")

![[Pasted image 20231120111911.png]]
To see why the multiplication rule is true, imagine a tree diagram as in the figure. Let the tree branch $a$ ways according to the possibilities for Experiment $A$, and for each of those branches create $b$ further branches for Experiment B. Overall, there are $\underbrace{b+b+\cdots+b}_a=a b$ possibilities.

## Sampling
**Theorem 1.4.7 (Sampling with replacement).** Consider $n$ objects and making $k$ choices from them, one at a time with replacement (i.e., choosing a certain object does not preclude it from being chosen again). Then there are $n^k$ possible outcomes

**Theorem 1.4.8 (Sampling without replacement).** Consider $n$ objects and making $k$ choices from them, one at a time without replacement (i.e., choosing a certain object precludes it from being chosen again).

Then there are $n(n-1) \cdots(n-k+1)$ possible outcomes for $1 \leq k \leq n$, and 0 possibilities for $k>n$ (where order matters). By convention, $n(n-1) \cdots(n-k+1)=n$ for $k=1$.

## Permutations
A *permutation* of $1,2, \ldots, n$ is an arrangement of them in some order, e.g., $3,5,1,2,4$ is a permutation of $1,2,3,4,5$. 

By **Theorem 1.4.8** with $k=n$, there are $n!$ permutations of $1,2, \ldots, n$.

## Binomial coefficient
**Definition 1.4.14 (Binomial coefficient).** For any nonnegative integers $k$ and $n$, the binomial coefficient $\left(\begin{array}{l}n \\ k\end{array}\right)$, read as " $n$ choose $k$ ", is the number of subsets of size $k$ for a set of size $n$.

For example, $\left(\begin{array}{l}4 \\ 2\end{array}\right)=6$,. The binomial coefficient $\left(\begin{array}{l}n \\ k\end{array}\right)$ is sometimes called a combination, but we do not use that terminology here since "combination" is such a useful general-purpose word. Algebraically, binomial coefficients can be computed as follows.

**Theorem 1.4.15 (Binomial coefficient formula).** For $k \leq n$, we have
$$
\left(\begin{array}{l}
n \\
k
\end{array}\right)=\frac{n(n-1) \cdots(n-k+1)}{k !}=\frac{n !}{(n-k) ! k !} .
$$
# Lecture notes

**Practice**:
- Non-obligatory assignments
- Quizzes


## Sets 
**Set difference**: $A\backslash B$ denotes the elements in $A$ but not in $B$.

The number of ordered sets 
## Example coin toss
1. Let $A_1$ be the event that the first flip is Heads. As a set,
$$
A_1=\left\{\left(1, s_2, \ldots, s_{10}\right): s_j \in\{0,1\} \text { for } 2 \leq j \leq 10\right\} .
$$

This is a subset of the sample space, so it is indeed an event; saying that $A_1$ occurs is the same thing as saying that the first flip is Heads. 

Similarly, let $A_j$ be the event that the $j$ th flip is Heads for $j=2,3, \ldots, 10$.

2. Let $B$ be the event that at least one flip was Heads. As a set,
$$
B=\bigcup_{j=1}^{10} A_j .
$$

3. Let $C$ be the event that all the flips were Heads. As a set,
$$
C=\bigcap_{j=1}^{10} A_j .
$$
4. Let $D$ be the event that there were at least two consecutive Heads. As a set,

Intuitively, we can see $\cap$ as a logical *AND* operator, and $\cup$  as a logical *OR* operator.

